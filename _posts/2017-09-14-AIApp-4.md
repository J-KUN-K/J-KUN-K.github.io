---
layout: post
title:  "SVM으로 소득 계층 분류하기(진행중)"
date:   2017-09-14 17:10:13 +0800
categories: machinelearning
tags: aiapp
---
** 서포트 벡터머신으로 소득 계층 분류를 해본다.**

---

서포트 벡터 머신은 클래수룰 구분하는 경계선을 직선이 아닌 초평면으로 표현한다. 여기서 초평면이란 쉽게 말해 직선을 N차원으로 표현한 것이다. 레이블이 달린 학습 데이터가 주어진 이진 분류 문제에 SVM을 적용하면 학습 데이터를 두 클래스로 가장 잘 나눌 수 있는 초 평면을 찾는다. 이러한 이진분류 기법은 N개의 클래스로 분류하는 문제로 쉽게 확장 할 수 있다.

SVM을 이용해 소득계층을 두 개의 클래스로 분류하는 실습을 해본다. 2차원이기 떄문에 시각화 방법이 편하고 기본 개념을 다룰 수 있다. 이를 통해 나중에 다룰 고차원 데이터도 제대로 다룰수 있게 선수실습을 한다.

{% highlight python linenos %}

import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsOneClassifier
from sklearn import cross_validation

# Input file containing data
input_file = 'income_data.txt'

# Read the data
X = []
y = []
count_class1 = 0
count_class2 = 0
max_datapoints = 25000

with open(input_file, 'r') as f:
    for line in f.readlines():
        if count_class1 >= max_datapoints and count_class2 >= max_datapoints:
            break

        if '?' in line:
            continue

        
        data = line[:-1].split(', ')
        
        if data[-1] == '<=50K' and count_class1 < max_datapoints:
            X.append(data)
            count_class1 +=1
        if data[-1] == '>50K' and count_class2 < max_datapoints:
            X.append(data)
            count_class2 +=1

# numpy 배열로 변환 
X = np.array(X)





# 문자열 데이터를 숫자 데이터로 변환하기
label_encoder = []
X_encoded = np.empty(X.shape)
for i, item in enumerate(X[0]):
    if item.isdigit():
        X_encoded[:, i] = X[:, i]
    else :
        label_encoder.append(preprocessing.LabelEncoder())
        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])

X = X_encoded[:, :-1].astype(int)
y = X_encoded[:, -1].astype(int)

# SVM 분류기 생성
classifier = OneVsOneClassifier(LinearSVC(random_state=0))

# 분류기 학습시키기
classifier.fit(X, y)

# 교차 검증
X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=5)
classifier = OneVsOneClassifier(LinearSVC(random_state=0))
classifier.fit(X_train, y_train)
y_test_pred = classifier.predict(X_test)

# SVM 분류기에 대한 F1 점수를 계산한다.
f1 = cross_validation.cross_val_score(classifier, X, y, scoring='f1_weighted', cv=3)
print("F1 score: " + str(round(100*f1.mean(), 2)) + '%')

# 테스트 데이터에 대한 출력 예측
input_data = ['37', 'Private', '215646', 'HS-grad', '9', 'Never-married', 'Handlers-cleaners', 'Not-in-family', 'White', 'Male', '0', '0', '40', 'United-States']

# 테스트 데이터 인코딩
input_data_encoded = [-1] * len(input_data)
count = 0
for i, item in enumerate(input_data):
    if item.isdigit():
        input_data_encoded[i] = int(input_data[i])
    else:
        input_data_encoded[i] = int(label_encoder[count].transform(input_data[i]))
        count += 1 

input_data_encoded = np.array(input_data_encoded)

# 인코딩한 데이터에 분류기를 실행하기 결과 출력
predicted_class = classifier.predict(input_data_encoded)
print(label_encoder[-1].inverse_transform(predicted_class)[0])



{% endhighlight %}

##### 코드에 에러가 발생하고 이론에 대한 코드 접근을 이해를 못하고 있다. 관련 문서좀 찾아봐야 할듯 싶다.