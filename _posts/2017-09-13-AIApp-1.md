---
layout: post
title:  "지도학습 및 비지도 학습 - 데이터 전처리와 레이블 인코딩"
date:   2017-09-13 17:00:13 +0800
categories: machinelearning
tags: [machinelearning, machinelearning]
comments: 1
---
**지도 학습, 비지도 학습 개념 및 머신 러닝을 구현하기 위해 사용되는 데이터 전처리 방법과 레이블 인코딩 방법을 알아본다.**

---

##### 지도 및 비지도 학습

기계에 지능을 부여하기 위한 대표적인 방법은 머신러닝을 활용하는 것입니다. 머신러닝은 크게 지도 학습과 비지도 학습으로 구분되죠. (그 외 방법도 존재합니다.)
지도 학습(Supervised learning)은 레이블이 달린 데이터로 학습 모델을 만듭니다. 예를 들어 나이, 학력, 거주지 같은 매개변수로 개인의 소득을 예측하는 시스템을 구축하려면
먼저 여러 사람에 대한 구체적인 정보를 모은 후 항목마다 레이블을 달아서 데이터베이스를 구축합니다. 이렇게 여러가지 매개변수와 소득의 관계가 정의 된 데이터베이스를
학습 알고리즘에 전달하면 특정한 여러사람에 대한 매개변수가 주어졌을 때 그사람의 소득을 계산하는 방법을 학습하는 것이 지도 학습입니다..
비지도 학습은 레이블이 달리지 않은 데이터로 학습 모델을 만듭니다. 데이터에 레이블이 달려있지 않기 때문에, 데이터 내용만으로 의미 있는 정보를 추출해야 합니다.
예를 들어특정 데이터 집합에 속한 데이터들을 여러개의 그룹으로 나눌때 비 지도 학습을 적용 가능하다. 이때 가장 어려운 점이 나누는 기준이 명확하지 않다는 것입니다.

##### 분류
분류란 데이터를 지정한 수만큼의 클래수로 나누는 기법입니다. 분류 기법은 데이터를 가장 효과적이면서 효울적으로 활용하도록 일정한 수의 그룹으로 데이터를 분류합니다. 머신 러닝에서는주어진 데이터 항목이 속하는 클래스를 결정하는 문제를 다룰 때 분류 기법을 사용합니다.

###### 데이터전처리
머신 러닝을 구현할 떄는 현실 세계에서 추출한 방대한 양의 미가공 데이터를 다룹니다. 이러한 데이터로 머신 러닝 알고리즘을 학습시키기 전에 먼저 데이터의 포맷을 머신 러닝 알고리즘이 처리할 수 있는 형태로 변환하는 전처리 작업부터 해야 하는데 이를 데이터전처리라 합니다. 
데이터 전처리에 사용되는 대표적인 방법들을 살펴 보겠습니다.


##### 샘플 배열 설정

{% highlight  python linenos  %}
import numpy as np
from sklearn import preprocessing
input_data = np.array([
    [5.1, -2.9, 3.3],
    [-1.2, 7.8, -6.1],
    [3.9, 0.4, 2.1],
    [7.3, -9.9, -4.5]
])
{% endhighlight %}

##### 이진화
이진화란 숫자를 임계값을 기준으로 불리언수로 변환하는 기법이다. 

{% highlight python linenos  %}
#이진화코드
data_binarized = preprocessing.Binarizer(threshold=2.1).transform(input_data)
print("\nBinarized : \n", data_binarized)

#결괏값
Binarized : 
 [[ 1.  0.  1.]
 [ 0.  1.  0.]
 [ 1.  0.  0.]
 [ 1.  0.  0.]]
{% endhighlight %}
##### 평균제거
 특징 벡터의 값들이 0을 중심으로 분포하게 만들고자 할때 많이 사용, 특징 벡터에 담긴 값들이 한쪽으로 치우치지 않게 할때 사용한다. 결괏값을 표현 평균0 표준편차1 정도로 조정 된것을 확인가능하다.

{% highlight python linenos  %}
# 평균 제거 코드
print("\nBefore : ")
print("Mean = ", input_data.mean(axis=0))
print("Std deviation = ", input_data.std(axis=0))
data_scaled = preprocessing.scale(input_data)

print("\nAfter : ")
print("Mean = ", data_scaled.mean(axis=0))
print("Std deviation = ", data_scaled.std(axis=0))

#결괏값

Before : 
Mean =  [ 3.775 -1.15  -1.3  ]
Std deviation =  [ 3.12039661  6.36651396  4.0620192 ]

After : 
Mean =  [  1.11022302e-16   0.00000000e+00   2.77555756e-17]
Std deviation =  [ 1.  1.  1.]
{% endhighlight %}

##### 크기조정
일정하지 않은 벡터의 각 요소 값을 동일 선상에서 비교 할 수 있도록 각각 특징에 대한 값을 일정 범위 내로 조정하는 과정이다.
단순히 측정 단위로 인해 값이 비정상적으로 클 수 있기 때문이다. 각 행은 최댓값은 1로 나머지는 이에 상대적인 값으로 조정된다.

{% highlight ruby %}
#크기 조정
data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))
data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)
print("\nMin max scaled data:\n", data_scaled_minmax)

#결괏값
Min max scaled data:
 [[ 0.74117647  0.39548023  1.        ]
 [ 0.          1.          0.        ]
 [ 0.6         0.5819209   0.87234043]
 [ 1.          0.          0.17021277]]
{% endhighlight %}

##### 정규화
특정 벡터의 값을 일정한 기준으로 측정하려면 정규화 과정을 거친다. 머신러닝에서는 다양한 형태의 정규화 기법을 거친다. 대표적으로 총합이 1이 되게 조정하는 L1정규화(최소 절대 편차) 그리고 L2 정규화(최소 제곱)는 제곱의 합이 1이 되도록 조정한다.

{% highlight ruby %}
#크기 조정
data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))
data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)
print("\nMin max scaled data:\n", data_scaled_minmax)

#결괏값
Min max scaled data:
 [[ 0.74117647  0.39548023  1.        ]
 [ 0.          1.          0.        ]
 [ 0.6         0.5819209   0.87234043]
 [ 1.          0.          0.17021277]]
{% endhighlight %}

##### 레이블 인코딩

{% highlight ruby %}
import numpy as np
from sklearn import preprocessing

# 샘플 입력 레이블
input_labels = ['red', 'black', 'red', 'green', 'black', 'yellow', 'white', 'red', 'green' ]

# 레이블 인코더 생성 후 앞에서 정의한 레이블로  학습시키기
encoder = preprocessing.LabelEncoder()
encoder.fit(input_labels)

print(encoder)

print(encoder.classes_)

# 매핑 관계 출력
print("\nLabel mapping : ")
for i, item in enumerate(encoder.classes_):
    print(item, '-->', i)
    
# 레이블 인코딩
test_labels = ['green', 'red', 'black']
encoded_values = encoder.transform(test_labels)
print("\nLabels = ",test_labels)
print("Encoded values = ", list(encoded_values))


#숫자 값 인코딩
encoded_values = [3, 4, 0, 1]
decoded_list = encoder.inverse_transform(encoded_values)
print("\nEncoded values = ", encoded_values)
print("Decoded labels = ", list(decoded_list))

# 결괏값 
LabelEncoder()
['black' 'green' 'red' 'white' 'yellow']

Label mapping : 
black --> 0
green --> 1
red --> 2
white --> 3
yellow --> 4

Labels =  ['green', 'red', 'black']
Encoded values =  [1, 2, 0]

Encoded values =  [3, 4, 0, 1]
Decoded labels =  ['white', 'yellow', 'black', 'green']
{% endhighlight %}
